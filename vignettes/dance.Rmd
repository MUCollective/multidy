---
title: "Recreating `Adding inferential treatments to plots using Resampling and Animations` using multidy"
author: "Abhraneel Sarma"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteIndexEntry{Recreating `Adding inferential treatments to plots using Resampling and Animations` using multidy}
  %\usepackage[UTF-8]{inputenc}
---


```{r setup, include=FALSE}
library(knitr)
opts_knit$set(
  echo = TRUE,
  fig.width = 6, 
  fig.height = 4,
  output.dir="vignettes"
)
library(dplyr)
library(tidyr)
library(ggplot2)
library(purrr)
library(broom)
library(gganimate)
library(multiverse)
```

## Introduction

In this document, we recreate the mini-paper [Adding Inferential Information to plots using Resampling and Animations](https://explorablemultiverse.github.io/examples/dance/) using the **multidy** package.

The mini-paper presents a method for adding inferential information to arbitrary statistical plots based on resampling and animation. A large number of bootstrap datasets are created and subjected to the same analyses and plotting procedures than the original dataset. These “bootstrap plots” are then animated to reveal the statistical noise that was hidden in the original plot, in order to help readers appreciate the uncertainty in the quantities, trends and patterns conveyed by the plot. The data used in this example is from a real study taken from the information visualization literature.


## The data

The data presented here was collected by Harrison et al. [](https://doi.org/10.1109/TVCG.2014.2346979). The goal of their study was to rank nine existing visualizations in their ability to effectively convey correlations. We focus on experiment 2, which was the main experiment and for which data and analysis code are available. In that experiment, nine visualizations were evaluated on 1,600+ crowdsourcing workers on their ability to convey correlation. The staircase method was used to derive just-noticeable difference (JND) values, which capture discrimination capacity: the lower the value, the better the participant can discriminate between correlations.

The experiment involved four independent variables: the visualization type (9 levels), the base correlation value (6 levels), whether the correlation was positive or negative (2 levels), and whether the value was approached from above or from below (2 levels). Each participant carried out 4 tasks, each with a specific combination of conditions.

First, we will quickly show what the original data, and the plots created using this dataset, looks like:

```{r, data}
data("vis_correlation")

df <- vis_correlation %>% 
  group_by( vis, rbase, approach, sign ) %>%
  select(-c(condition, visandsign, participant)) %>%
  summarise( jnd = list(jnd) ) %>%
  mutate( 
    median = map_dbl(jnd, ~median(.x)),
    mads = map_dbl(jnd, ~mad(.x, constant = 1)),
    jnd_limit = 3 * mads
  ) %>% 
  ungroup()
```


```{r, data-proc-errorbars}
df.error_bar <- df %>%
  unnest( cols = c(jnd) ) %>%
  filter( abs(jnd - median) <= jnd_limit ) %>%
  group_by( vis, rbase, approach, sign ) %>%
  summarise( jnd = list(jnd) ) %>%
  mutate(
    sd = map_dbl(jnd, ~sd(.x)/sqrt(length(.x))),
    mean = map_dbl(jnd, ~mean(.x))
  )
```

### Just Noticeable Differences (JNDs)

The following figure shows the mean JND for each of the 216 conditions, each displayed as a dot. We show JND as a function of correlation *r* for both above (light points) and below (dark points) approaches.

```{r, fig.height = 8, fig.width = 8}
df.error_bar %>%
  ggplot() +
  geom_errorbar(aes(x = rbase, ymin = (mean - sd), ymax = mean + sd, color = approach), width = 0.025) +
  geom_point( aes(x = rbase, y = mean, color = approach )) +
  geom_hline( yintercept = 0.45, linetype = "dashed", alpha = 0.25) +
  geom_abline( slope = -1, intercept = 1, linetype = "dashed", alpha = 0.25) +
  facet_wrap(vis ~ sign, ncol = 4)
```

### Regression results

The next figure shows the regression lines for all conditions, as well as the results from a [previous similar experiment](https://doi.org/10.1111/j.1467-8659.2009.01694.x). The figure is consistent with the paper’s main findings: ”using scatterplots to depict correlation results in better performance overall. However, this performance difference only occurs when depicting positively correlated data. In fact, parallel coordinates depicting negatively correlated data appear to perform as well as scatterplots”

```{r, data-proc-regression-1}
filter_outliers <- function(x, median, limit) {
  return( x[abs(x - median) <= limit] )
}

df.corr <- df %>%
  # the following visualizations were excluded from the analysis
  filter( !((vis == "donut" | vis == "stackedarea" | vis == "stackedline" | vis == "stackedbar") & (sign == 1)) & !((vis == "radar" | vis == "line") & (sign == -1)) ) %>%
  mutate( jnd = pmap(list(jnd, median, jnd_limit), filter_outliers) ) %>%
  mutate( 
    mean_jnd = map_dbl(jnd, mean),
    n = map_dbl(jnd, length)
  )
```


```{r, data-proc-regression-2}
rbase_adj_coef <- df.corr %>%
  group_by( vis, sign, rbase ) %>%
  summarise( jnd = list(jnd), mean_jnd = list(mean_jnd), n = list(n), approach = list(approach) ) %>%
  mutate( rbase_adj_coef = map2_dbl(mean_jnd, n, ~ sum(.x * .y) / sum(.y)) ) %>%
  mutate( rbase_adj_coef = map2_dbl(mean_jnd, n, ~ sum(.x * .y) / sum(.y)) ) %>%
  unnest(cols = c(jnd, mean_jnd, approach) ) %>%
  magrittr::extract2("rbase_adj_coef")

df.corr_fitted <- df.corr %>%
  tibble::add_column( rbase_adj_coef = rbase_adj_coef ) %>%
  mutate( 
    multiplier = ifelse(approach == "above", 1, -1),
    rbase = rbase + 0.5 * multiplier * rbase_adj_coef
  ) %>%
  group_by( vis, sign ) %>%
  summarise( mean_jnd = list(mean_jnd), rbase = list(rbase) ) %>%
  mutate( 
    fit = map2(rbase, mean_jnd, ~as.list(coef(lm(.y ~ .x)))),
    sign = factor(ifelse(sign == 1, "positive", "negative"), levels = c("positive", "negative"))
  ) %>%
  unnest_wider( col = c(fit) ) %>%
  rename( intercept = `(Intercept)`, coef = .x ) %>%
  mutate(
    x = 0, 
    xend = 1,
    y = intercept + coef * x,
    yend = intercept + coef * xend
  )
```


```{r, regression-vis, fig.width = 8, fig.height = 5}
df.corr_fitted %>%
  ggplot() +
  geom_segment( aes( x=x, y=y, xend=xend, yend=yend, color = vis, linetype = sign) ) +
  coord_cartesian( xlim = c(0, 1), ylim = c(0, 0.6) ) +
  scale_y_continuous( breaks = seq(0, 1, by = 0.1)) +
  scale_x_continuous( breaks = seq(0, 1, by = 0.2))
```


```{r}
#data_original <- read.csv("master-alt.csv")
n = 200

M = multiverse()

inside(M, {
  set.seed(branch(seed, .options = 1:n))
  
  data.i = vis_correlation %>%
    group_by(rbase, sign, vis, approach) %>%
    summarise( jnd = list(jnd), .groups = "drop" ) %>%
    mutate( 
      sample_size = map_dbl(jnd, length ),
      bootstrap_samples = map(jnd, ~ sample( .x, size = sample_size, replace = TRUE))
    ) %>%
    select(-jnd) %>%
    unnest( cols = c(bootstrap_samples)) %>%
    rename( jnd = bootstrap_samples )
  
  df.i <- data.i %>% 
    group_by( vis, rbase, approach, sign ) %>%
    summarise( jnd = list(jnd) ) %>%
    mutate( 
      median = map_dbl(jnd, ~median(.x)),
      mads = map_dbl(jnd, ~mad(.x, constant = 1)),
      jnd_limit = 3 * mads
    ) %>% 
    ungroup()
})
```


```{r}
inside(M, {
  df.error_bar.i <- df.i %>%
    unnest( cols = c(jnd) ) %>%
    filter( abs(jnd - median) <= jnd_limit ) %>%
    group_by( vis, rbase, approach, sign ) %>%
    summarise( jnd = list(jnd) ) %>%
    mutate(
      sd = map_dbl(jnd, ~sd(.x)/sqrt(length(.x))),
      mean = map_dbl(jnd, ~mean(.x))
    )
  
  df.corr.i <- df.i %>%
      # the following visualizations were excluded from the analysis
      filter( !((vis == "donut" | vis == "stackedarea" | vis == "stackedline" | vis == "stackedbar") & (sign == 1)) & !((vis == "radar" | vis == "line") & (sign == -1)) ) %>%
      mutate( jnd = pmap(list(jnd, median, jnd_limit), filter_outliers) ) %>%
      mutate( 
        mean_jnd = map_dbl(jnd, mean),
        n = map_dbl(jnd, length)
      )
  
  rbase_adj_coef.i <- df.corr.i %>%
      group_by( vis, sign, rbase ) %>%
      summarise( jnd = list(jnd), mean_jnd = list(mean_jnd), n = list(n), approach = list(approach) ) %>%
      mutate( rbase_adj_coef = map2_dbl(mean_jnd, n, ~ sum(.x * .y) / sum(.y)) ) %>%
      mutate( rbase_adj_coef = map2_dbl(mean_jnd, n, ~ sum(.x * .y) / sum(.y)) ) %>%
      unnest(cols = c(jnd, mean_jnd, approach) ) %>%
      magrittr::extract2("rbase_adj_coef")
  
  df.corr_fitted.i <- df.corr.i %>%
      tibble::add_column( rbase_adj_coef = rbase_adj_coef ) %>%
      mutate( 
          multiplier = ifelse(approach == "above", 1, -1),
          rbase = rbase + 0.5 * multiplier * rbase_adj_coef
      ) %>%
      group_by( vis, sign ) %>%
      summarise( mean_jnd = list(mean_jnd), rbase = list(rbase) ) %>%
      mutate( 
          fit = map2(rbase, mean_jnd, ~as.list(coef(lm(.y ~ .x)))),
          sign = factor(ifelse(sign == 1, "positive", "negative"), levels = c("positive", "negative"))
      ) %>%
      unnest_wider( col = c(fit) ) %>%
      rename( intercept = `(Intercept)`, coef = .x ) %>%
      mutate(
          x = 0, 
          xend = 1,
          y = intercept + coef * x,
          yend = intercept + coef * xend
      )
})
```


```{r}
execute_multiverse(M)
```


```{r, vis-errorbars-above, fig.width = 8, fig.height = 5}
p.above <- multiverse_table(M) %>%
  mutate(data = map(.results, "df.error_bar.i")) %>%
  unnest( cols = c(data) ) %>%
  filter( sign == 1 ) %>%
  ggplot() +
  geom_errorbar(aes(x = rbase, ymin = (mean - sd), ymax = mean + sd, color = approach), width = 0.025) +
  geom_point( aes(x = rbase, y = mean, color = approach )) +
  geom_hline( yintercept = 0.45, linetype = "dashed", alpha = 0.25) +
  geom_abline( slope = -1, intercept = 1, linetype = "dashed", alpha = 0.25) +
  facet_wrap( ~ vis, nrow = 2) +
  transition_manual(.universe)

animate(p.above, nframes = n, fps = 3, width = 840, height = 320)
```



```{r, vis-errorbars-below}
p.below <- multiverse_table(M) %>%
  mutate(data = map(.results, "df.error_bar.i")) %>%
  unnest( cols = c(data) ) %>%
  filter( sign == -1 ) %>%
  ggplot() +
  geom_errorbar(aes(x = rbase, ymin = (mean - sd), ymax = mean + sd, color = approach), width = 0.025) +
  geom_point( aes(x = rbase, y = mean, color = approach )) +
  geom_hline( yintercept = 0.45, linetype = "dashed", alpha = 0.25) +
  geom_abline( slope = -1, intercept = 1, linetype = "dashed", alpha = 0.25) +
  facet_wrap( ~ vis, nrow = 2) +
  transition_manual(.universe)

animate(p.below, nframes = n, fps = 3, width = 840, height = 320)
```


```{r, vis-regression-lines}
p.fitted_lines <- multiverse_table(M) %>%
  mutate(data = map(.results, "df.corr_fitted.i")) %>%
  unnest( cols = c(data) ) %>%
  ggplot() +
  geom_segment( aes( x=x, y=y, xend=xend, yend=yend, color = vis, linetype = sign) ) +
  coord_cartesian( xlim = c(0, 1), ylim = c(0, 0.6) ) +
  scale_y_continuous( breaks = seq(0, 1, by = 0.1)) +
  scale_x_continuous( breaks = seq(0, 1, by = 0.2)) +
  transition_manual(.universe)

animate(p.fitted_lines, nframes = n, fps = 3, width = 840, height = 480)
```


